{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício Prático Semana 2\n",
    "### Informações Iniciais\n",
    "- Link da solução oficial do Dataquest [aqui](https://github.com/dataquestio/solutions/blob/master/Mission350Solutions.ipynb) \n",
    "- Link para baixar o data set contendo dados da plataforma GooglePlay [aqui](https://www.kaggle.com/datasets/lava18/google-play-store-apps)\n",
    "- Link para baixar o data set contendo dados da plataforma AppleStore [aqui](https://www.kaggle.com/datasets/ramamet4/app-store-apple-data-set-10k-apps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libs\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class para trabalhar o arquivo csv\n",
    "class Arquivo_Dados:\n",
    "  def __init__(self,arquivo):\n",
    "    opened_file = open(arquivo, encoding=\"utf8\")\n",
    "    read_file = reader(opened_file)\n",
    "    lista = list(read_file)\n",
    "    lista_header = lista[0]\n",
    "    lista = lista[1:]\n",
    "    self.header = lista_header\n",
    "    self.list = lista\n",
    "\n",
    "  def explore_data(self,start , end , rows_and_columns=False):\n",
    "    dataset_slice = self.list[start:end]    \n",
    "    for row in dataset_slice:\n",
    "      print(row)\n",
    "      print('\\n') # adds a new (empty) line between rows\n",
    "        \n",
    "    if rows_and_columns:\n",
    "      print('Number of rows:', len(self.list))\n",
    "      print('Number of columns:', len(self.list[0]))\n",
    "\n",
    "  def delete_line(self,line):\n",
    "    del self.list[line]\n",
    "\n",
    "  def duplicate_items(self , p_header , duplicate=True):\n",
    "    duplicate_lines = []\n",
    "    unique_lines = []\n",
    "    for line in self.list:\n",
    "      item = line[p_header]\n",
    "      if item in unique_lines:\n",
    "        duplicate_lines.append(item)\n",
    "      else:\n",
    "        unique_lines.append(item)\n",
    "\n",
    "    print( \"Number of duplicate:\", (len(duplicate_lines) if duplicate else unique_lines))\n",
    "\n",
    "  # Função que identifica se determinada string tem mais de 3 caracteres fora do padrão ascii\n",
    "  def is_english(string):\n",
    "    non_ascii = 0\n",
    "    \n",
    "    for character in string:\n",
    "        if ord(character) > 127:\n",
    "            non_ascii += 1\n",
    "    return False if  non_ascii > 3 else True\n",
    "\n",
    "  def no_english_items(self , parameter):\n",
    "    no_english_list = []\n",
    "    for line in self.list:\n",
    "      if Arquivo_Dados.is_english(line[parameter]) == False:\n",
    "        no_english_list.append(line[parameter])\n",
    "    print(\"Number of no English Items: \", len(no_english_list))\n",
    "\n",
    "  def clean_no_english_items(self,parameter):\n",
    "    no_english_list = []\n",
    "    for line in self.list:\n",
    "      if Arquivo_Dados.is_english(line[parameter]) == False:\n",
    "        Arquivo_Dados.delete_line(self,self.list.index(line))\n",
    "    return self.list\n",
    "\n",
    "  def only_free(self, column):\n",
    "    dataset_free = []\n",
    "    for app in self.list:\n",
    "      price = app[column]\n",
    "      if price == '0' or price == '0.0':\n",
    "        dataset_free.append(app)\n",
    "    self.list = dataset_free\n",
    "\n",
    "  def freq_table(self, index):\n",
    "    table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in self.list:\n",
    "        total += 1\n",
    "        value = row[index]\n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "    \n",
    "    table_percentages = {}\n",
    "    for key in table:\n",
    "        percentage = (table[key] / total) * 100\n",
    "        table_percentages[key] = percentage \n",
    "    \n",
    "    return table_percentages\n",
    "\n",
    "\n",
    "def display_table(self, index):\n",
    "    table = Arquivo_Dados.freq_table(self, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "        \n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "\n",
    "\n",
    "    \n",
    "      \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "android = Arquivo_Dados('./googleplaystore.csv')\n",
    "ios = Arquivo_Dados('./AppleStore.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f995094313285ca45e02641952721eb82d851a2ebba119a240e7e1eae8de5dae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
